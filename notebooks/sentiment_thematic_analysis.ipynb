{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7a1287",
   "metadata": {},
   "source": [
    "# Sentiment and Thematic Analysis\n",
    "\n",
    "This notebook performs sentiment analysis and thematic analysis on mobile banking app reviews for CBE, BOA, and Dashen Bank. It uses DistilBERT for sentiment scoring and spaCy/TF-IDF for theme extraction.\n",
    "\n",
    "**Steps:**\n",
    "1. Load and preprocess cleaned data.\n",
    "2. Perform sentiment analysis with DistilBERT.\n",
    "3. Extract keywords and themes.\n",
    "4. Save results.\n",
    "\n",
    "**KPI:** Sentiment for 90%+ reviews, 3+ themes per bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906f981a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\AIM\\10_academy\\Week_2_challenge\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f30f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c5ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1180 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv(\"../Data/cleaned_reviews.csv\")  # Adjust path if needed\n",
    "print(f\"Loaded {len(df)} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c48c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to string, lowercase, remove special characters\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization and stop-word removal with spaCy\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "df[\"processed_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "print(\"Text preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669a7aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\AIM\\10_academy\\Week_2_challenge\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bed06561e95492c8f65a8368365356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\AIM\\10_academy\\Week_2_challenge\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9640607cdb06410ab24e7c0555ad7948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e65744bdde4c6bb73e52c6d6a664df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c36e2f533ec4a4a936d1de6317ee8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analyzed for 1180 reviews.\n"
     ]
    }
   ],
   "source": [
    "# Initialize DistilBERT sentiment pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "def get_sentiment(text):\n",
    "    result = sentiment_analyzer(text[:512])[0]  # Limit to 512 tokens\n",
    "    return result[\"label\"], result[\"score\"]\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df[[\"sentiment_label\", \"sentiment_score\"]] = df[\"review\"].apply(\n",
    "    lambda x: pd.Series(get_sentiment(x))\n",
    ")\n",
    "print(f\"Sentiment analyzed for {len(df[df['sentiment_label'].notna()])} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb2149c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Sentiment Score by Bank and Rating:\n",
      "                           bank  rating  sentiment_score\n",
      "0             Bank of Abyssinia       1         0.988881\n",
      "1             Bank of Abyssinia       2         0.981547\n",
      "2             Bank of Abyssinia       3         0.990526\n",
      "3             Bank of Abyssinia       4         0.978465\n",
      "4             Bank of Abyssinia       5         0.977828\n",
      "5   Commercial Bank of Ethiopia       1         0.988785\n",
      "6   Commercial Bank of Ethiopia       2         0.976726\n",
      "7   Commercial Bank of Ethiopia       3         0.969137\n",
      "8   Commercial Bank of Ethiopia       4         0.964873\n",
      "9   Commercial Bank of Ethiopia       5         0.966693\n",
      "10                  Dashen Bank       1         0.995097\n",
      "11                  Dashen Bank       2         0.960082\n",
      "12                  Dashen Bank       3         0.997640\n",
      "13                  Dashen Bank       4         0.978575\n",
      "14                  Dashen Bank       5         0.986615\n"
     ]
    }
   ],
   "source": [
    "sentiment_agg = df.groupby([\"bank\", \"rating\"]).agg({\"sentiment_score\": \"mean\"}).reset_index()\n",
    "print(\"\\nMean Sentiment Score by Bank and Rating:\")\n",
    "print(sentiment_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4383a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Keywords per Bank (TF-IDF):\n",
      "Commercial Bank of Ethiopia: ['app', 'transaction', 'update', 'work', 'transfer']\n",
      "Bank of Abyssinia: ['app', 'work', 'update', 'bank', 'use']\n",
      "Dashen Bank: ['app', 'good', 'bank', 'banking', 'use']\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=10, stop_words=\"english\")\n",
    "tfidf_matrix = tfidf.fit_transform(df[\"processed_review\"])\n",
    "keywords = tfidf.get_feature_names_out()\n",
    "print(\"\\nTop Keywords per Bank (TF-IDF):\")\n",
    "for bank in df[\"bank\"].unique():\n",
    "    bank_reviews = df[df[\"bank\"] == bank][\"processed_review\"]\n",
    "    bank_tfidf = tfidf.transform(bank_reviews)\n",
    "    avg_tfidf = np.mean(bank_tfidf.toarray(), axis=0)\n",
    "    bank_keywords = [keywords[i] for i in avg_tfidf.argsort()[-5:][::-1]]\n",
    "    print(f\"{bank}: {bank_keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b143f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Themes Assigned:\n",
      "                          bank  \\\n",
      "0  Commercial Bank of Ethiopia   \n",
      "1  Commercial Bank of Ethiopia   \n",
      "2  Commercial Bank of Ethiopia   \n",
      "3  Commercial Bank of Ethiopia   \n",
      "4  Commercial Bank of Ethiopia   \n",
      "\n",
      "                                              review  \\\n",
      "0  The CBE app has been highly unreliable in rece...   \n",
      "1  this new update(Mar 19,2025) is great in fixin...   \n",
      "2  Good job to the CBE team on this mobile app! I...   \n",
      "3  this app has developed in a very good ways but...   \n",
      "4  everytime you uninstall the app you have to re...   \n",
      "\n",
      "                        themes  \n",
      "0                        Other  \n",
      "1                        Other  \n",
      "2  User Interface & Experience  \n",
      "3                        Other  \n",
      "4                        Other  \n"
     ]
    }
   ],
   "source": [
    "# Define themes based on keywords (manual grouping)\n",
    "themes_dict = defaultdict(list)\n",
    "keyword_themes = {\n",
    "    \"login\": \"Account Access Issues\",\n",
    "    \"error\": \"Account Access Issues\",\n",
    "    \"crash\": \"Reliability\",\n",
    "    \"slow\": \"Transaction Performance\",\n",
    "    \"transfer\": \"Transaction Performance\",\n",
    "    \"ui\": \"User Interface & Experience\",\n",
    "    \"design\": \"User Interface & Experience\",\n",
    "    \"support\": \"Customer Support\",\n",
    "    \"help\": \"Customer Support\",\n",
    "    \"feature\": \"Feature Requests\"\n",
    "}\n",
    "\n",
    "def assign_themes(review):\n",
    "    themes = set()\n",
    "    doc = nlp(review)\n",
    "    for token in doc:\n",
    "        if token.text in keyword_themes:\n",
    "            themes.add(keyword_themes[token.text])\n",
    "    return \";\".join(themes) if themes else \"Other\"\n",
    "\n",
    "df[\"themes\"] = df[\"processed_review\"].apply(assign_themes)\n",
    "print(\"\\nSample Themes Assigned:\")\n",
    "print(df[[\"bank\", \"review\", \"themes\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2551d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved results for 1180 reviews to sentiment_thematic_results.csv.\n"
     ]
    }
   ],
   "source": [
    "# Add review_id\n",
    "df[\"review_id\"] = range(len(df))\n",
    "# Save to CSV\n",
    "df[[\"review_id\", \"review\", \"sentiment_label\", \"sentiment_score\", \"themes\"]].to_csv(\"../Data/sentiment_thematic_results.csv\", index=False)\n",
    "print(f\"\\nSaved results for {len(df)} reviews to sentiment_thematic_results.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
